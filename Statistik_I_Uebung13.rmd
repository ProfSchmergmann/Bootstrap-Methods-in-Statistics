---
title: "Mathematische Statistik I Übung 13"
output: html_notebook
author: Sven Bergmann
---

## Aufgabe 1
1. Seien $Y \sim \text{EXP}(\lambda)$ und $Y \sim \text{EXP}(\mu)$ unabhängig, mit $\lambda\in(0,\infty) und $\mu\in(0,\infty)$ unbekannt. Sei $X = (Y, \min(Y,Z))\top$.

a) Bestimmen Sie die Randverteilungen von $X$.

b) Seien $X_1, \ldots, X_n$ unabhängig, je mit derselben Verteilung wie $X$. Gegeben seien $\lambda_0\in(0,\infty)$ und $\mu_0\in(0,\infty)$. Schlagen Sie unter Verwendung der Methode von Bonferroni einen Test zum Testniveau $\alpha\in(0,\infty)$ für das Testproblem
$$H:\lambda = \lambda_0 \text{ und } \mu = \mu_0, K: \lambda\neq\lambda_0 \text{ oder } \mu\neq\mu_0$$
basierend auf Beobachtungen von $X_1, \ldots, X_n$ vor. Überprüfen Sie für $\lambda_0=1$, $\mu_0=2$, $n = 10$ und $\alpha = 0.05$ mittels Simulation wie gut der Test das Testniveau einhält.
```{r}
draw_x <- function(n, lambda, mu) {
  y <- rexp(n = n, rate = lambda)
  return(cbind(y, pmin(y, rexp(n = n, rate = mu))))
}
```
```{r}
x <- draw_x(n = 10, lambda = 1, mu = 2)
```
## Aufgabe 2

Zu bekannten gegebenen Werten $t_i$ wurden die in der nachfolgenden Tabelle festgehaltenen Beobachtungswerte $x_i$ von Zufallsvariablen $X_i$ erhalten.

| $t_i$ | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|-------|---|---|---|---|---|---|---|---|---|---|
| $x_i$ | 1 | 1 | 2 | 3 | 5 | 3 | 7 | 6 | 8 | 9 |

Es liege das Modell
$$X_i = a + bt_i + Z_i, a, b \in\mathbb{R}$$
unbekannt,
mit unabhängigen $\mathcal{N}(0, \sigma^2)$-verteilten Zufallsvariablen $Z_1, \ldots, Z_n$,
je mit derselben unbekannten Varianz $\sigma^2 > 0$ zugrunde.
Es sei $t_0 = 3.8$.
Geben Sie ein Konfidenzintervall zum Konfidenzniveau $0.95$ für $a + bt_0$ an.
```{r}
x <- c(1, 1, 2, 3, 5, 3, 7, 6, 8, 9)
t <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)
n <- length(x)
t_0 <- 3.8
gamma <- 0.95
```
Aus Beispiel 3.3:

Tausche die Namen wegen der Vorschrift für $X_i$.

Modell: $X_i = a + bt_i + Z_i, a, b \in\mathbb{R}$.

Setze nun $\sigma_t^2 = \frac{1}{n}\sum\limits_{i=1}^{n}(t_i-\overline{t})^2$ mit $\overline{t}=\frac{1}{n}\sum\limits_{i=1}^{n}t_i$ und $y_j = \frac{t_j-\overline{t}}{\sigma_t}, j=1, \ldots, n$.
```{r}
t_bar <- mean(t)
sigma_t_hat_squared <- (1 / n) * sum((t - t_bar)^2)
y <- (t - t_bar) / sqrt(sigma_t_hat_squared)
```
Dann sind die ML Schätzer:
$$\hat{\alpha} = \bar{X}$$
$$\hat{\beta} = \bar{Xy}$$
$$\hat{\sigma}^2 = \bar{X^2} - \bar{X}^2 - \bar{Xy}^2$$
```{r}
x_bar <- mean(x)
alpha_hat <- x_bar

x_y_bar <- mean(x * y)
beta_hat <- x_y_bar

sigma_hat_squared <- mean(x^2) - x_bar^2 - x_y_bar^2

c <- qt(df = n - 1, p = 1 - (gamma / 2))
term <- c * sqrt((sigma_hat_squared / (n - 2)) * (1 + t_0^2))
ci_lower <- alpha_hat + beta_hat * t_0 - term
ci_upper <- alpha_hat + beta_hat * t_0 + term

cat('Das Konfidenzintervall zum Konfidenzniveau', gamma, 'ist: [', ci_lower, ',', ci_upper, '], mit einer Breite von', ci_upper - ci_lower, '.')

```
## Aufgabe 3

Die Resultate von gleichgenauen Messungen der Eindringtiefe $x_i$ eines Projektils in ein Hindernis bei verschiedenen einstellbaren Werten seiner spezifischen Energie $v_i$ (d.h. Energie pro Einheitsfläche des Hindernisses) sind in der nachfolgenden Tabelle angegeben.

| $v_i$ | 41 | 50 | 81 | 104 | 120 | 139 | 154 | 180 | 208 | 241 | 250 | 269 | 301 |
|-------|----|----|----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|
| $x_i$ | 4  | 8  | 10 | 14  | 16  | 20  | 19  | 23  | 26  | 30  | 31  | 36  | 37  |

Nehmen Sie an, dass die beobachteten Eindringtiefen ermittelte Werte von unabhängigen Zufallsvariablen $X_i \sim \mathcal{N}(a + bv_i, \sigma^2)$ mit unbekannten Parametern $a, b \in\mathbb{R}$ und $\sigma^2 > 0$ sind.
Erstellen Sie eine grafische Darstellung des Konfidenzgürtels zum Konfidenzniveau 0.95 für $a + bv$, $v \in\mathbb{R}$.
```{r}
x <- c(4, 8, 10, 14, 16, 20, 19, 23, 26, 30, 31, 36, 37)
n <- length(x)
v <- c(41, 50, 81, 104, 120, 139, 154, 180, 208, 241, 250, 269, 301)
gamma <- 0.95
```
Aus Beispiel 3.3:

Tausche die Namen wegen der Vorschrift für $X_i$.

Modell: $X_i \sim \mathcal{N}(a + bv_i, \sigma^2)$.

Setze nun $\sigma_v^2 = \frac{1}{n}\sum\limits_{i=1}^{n}(v_i-\overline{v})^2$ mit $\overline{v}=\frac{1}{n}\sum\limits_{i=1}^{n}v_i$ und $y_j = \frac{v_j-\overline{v}}{\sigma_v}, j=1, \ldots, n$.
```{r}
v_bar <- mean(v)
sigma_v_hat_squared <- (1 / n) * sum((v - v_bar)^2)
y <- (v - v_bar) / sqrt(sigma_v_hat_squared)
```
Dann sind die ML Schätzer:
$$\hat{\alpha} = \bar{X}$$
$$\hat{\beta} = \bar{Xy}$$
$$\hat{\sigma}^2 = \bar{X^2} - \bar{X}^2 - \bar{Xy}^2$$
```{r}
x_bar <- mean(x)
alpha_hat <- x_bar

x_y_bar <- mean(x * y)
beta_hat <- x_y_bar

sigma_hat_squared <- mean(x^2) - x_bar^2 - x_y_bar^2
```
```{r}
conf_guertel_schaetzer <- function(alpha_hat, beta_hat, t, n, gamma, sigma_hat_squared, lower) {
  term <- sqrt((2 / (n - 2)) *
                 qf(p = 1 - gamma, df1 = 2, df2 = n - 2) *
                 sigma_hat_squared *
                 (1 + t^2))
  return(ifelse(lower,
                alpha_hat + beta_hat * t - term,
                alpha_hat + beta_hat * t + term))
}
```
```{r}
plot(v ~ x, main = 'Originaldaten')
plot(x, y, main = 'Normalisierte Daten')
schaetzer_upper <- lapply(X = x, FUN = function(x) conf_guertel_schaetzer(alpha_hat = alpha_hat, beta_hat = beta_hat, t = x, n = n, gamma = gamma, sigma_hat_squared = sigma_hat_squared, lower = FALSE))
schaetzer_lower <- lapply(X = x, FUN = function(x) conf_guertel_schaetzer(alpha_hat = alpha_hat, beta_hat = beta_hat, t = x, n = n, gamma = gamma, sigma_hat_squared = sigma_hat_squared, lower = TRUE))
plot(x, v, main = 'green: untere Grenze, red: obere Grenze des Konfidenzguertelschaetzers')
# points(x, schaetzer_lower, col = 'green')
lines(x, schaetzer_lower, col = 'green')
# points(x, schaetzer_upper, col = 'red')
lines(x, schaetzer_upper, col = 'red')

```

